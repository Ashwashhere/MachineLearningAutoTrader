{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d43737e",
   "metadata": {},
   "source": [
    "# <font color=\"Blue\">Autotrader Machine Learning Predictive Modelling</font>\n",
    "\n",
    "This Notebook implements a standard Machine Learning Pipeline to address a real-world Machine Learning problem: **predicting the selling price of a car**\n",
    "using the \"Car Sale Adverts\" Dataset provided by Autotrader. \n",
    "\n",
    "The steps to achieve this are broken down below: \n",
    "\n",
    "1. **Data/Domain Understanding and Exploration:** Loading, analysing and visualising the datasets features. \n",
    "\n",
    "2. **Data Processing for Machine Learning:** Cleaning the data (handling missing data, outliers and noise) and performing feature engineering and transformations. \n",
    "\n",
    "3. **Model Building:** Fitting, tuning and selectig models. This will include k-Nearest Neighbours, Decision Tree Classifier, Linear Regression and Random Forest. \n",
    "\n",
    "4. **Model Evaluation and Analysis:** Evaluating the various models using variouis metrics, analysing feature importance, and inspecting individual predictions erros.\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47203551",
   "metadata": {},
   "source": [
    "## <font color=\"Blue\">Packages</font>\n",
    "\n",
    "The following section of code imports all relevant Python packages grouped by functionality. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be05c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data Processing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import Visualisation Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Other Imports \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0bfb46",
   "metadata": {},
   "source": [
    "## <font color=\"Blue\">Initial Data Exploration</font>\n",
    "\n",
    "The following cells perform an initial exploration of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0315f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('adverts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf2503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the first 5 observations\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2a06e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Data\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out dataframe information \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f2e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Inspection and Classification \n",
    "# Function to Classify Features \n",
    "def summarise_features(df, max_cardinality=100):\n",
    "    # Empty list to store summary data for each column\n",
    "    rows = []\n",
    "    # Loops through each column name in the DataFrame\n",
    "    for col in df.columns:\n",
    "        # Select entire column as a series\n",
    "        s = df[col]\n",
    "        # Get datatype of column\n",
    "        dtype = str(s.dtype)\n",
    "        # Get number of unique values\n",
    "        n_unique = s.nunique(dropna=True)\n",
    "        # Calculate percentage of mising values by using mean on null values rounded to 3 decimal places\n",
    "        pct_missing = round(s.isna().mean(), 3)\n",
    "        # Check if data type is numerical\n",
    "        if pd.api.types.is_numeric_dtype(s):\n",
    "            # Set features type\n",
    "            ftype = 'numerical'\n",
    "            # Check if data is a datetime object\n",
    "        elif pd.api.types.is_datetime64_any_dtype(s):\n",
    "            # Set feature type to datetime\n",
    "            ftype = 'datetime'\n",
    "        else: \n",
    "            # Check if feature is categorical (can use one hot encoding) or high_cardinality (can't use onehot encoding)\n",
    "            ftype = 'categorical' if n_unique <= max_cardinality else 'high_cardinality'\n",
    "            # Append dictionary of column data to rows list\n",
    "        rows.append({\n",
    "            'column': col,\n",
    "            'dtype': dtype,\n",
    "            'feature_type': ftype,\n",
    "            'n_unique': n_unique,\n",
    "            'pct_missing': pct_missing\n",
    "        })\n",
    "        # Convert rows list to a DataFrame and return\n",
    "    return pd.DataFrame(rows).sort_values(['feature_type', 'n_unique'], ascending=[True, False])\n",
    "\n",
    "feature_summary = summarise_features(df)\n",
    "display(feature_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a5b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Visualisation and Analysis\n",
    "\n",
    "# Feature Target\n",
    "target = 'price'\n",
    "# Drop ID Features\n",
    "cols_to_drop = ['public_reference', 'reg_code']\n",
    "\n",
    "# Create list of numerical column names \n",
    "num_cols = [c for c in df.select_dtypes(include='number').columns if c not in cols_to_drop]\n",
    "# Create a list of categorical feature names\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# 1. Histograms \n",
    "# Loop through numerical columns\n",
    "for col in num_cols:\n",
    "    # Create blank 6x3 figure\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    # Create histogram for column, dropping null values \n",
    "    sns.histplot(df[col].dropna(), kde=True, bins=30)\n",
    "    plt.title(f'{col} distribution')\n",
    "    plt.show() \n",
    "\n",
    "# 2. Boxplots to inspect outliers (numerical)\n",
    "# Create blank 12x4 figure\n",
    "plt.figure(figsize=(12, 4))\n",
    "# Draw  boxplots using a random sample (up to 1000 rows) for speed and orient them horizontally.\n",
    "sns.boxplot(data=df[num_cols].sample(n=min(1000, len(df))), orient='h')\n",
    "plt.title('Boxplots (sampled)')\n",
    "plt.show()\n",
    "\n",
    "# 3. Correlation heatmap (numerical)\n",
    "# Create balck 10x8 figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Calculate correlation matrix for all numerical columns\n",
    "corr = df[num_cols].corr()\n",
    "# Use seaborn to draw heatmap of calculated correlation matrix, \n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', square=True, vmin=-1, vmax=1)\n",
    "plt.title('Numeric feature correlations')\n",
    "plt.show()\n",
    "\n",
    "# 4. Scatter plots vs target for all numerical features\n",
    "# Check if the target variable exists and is in the list of numerical columns\n",
    "if target in df.columns and target in num_cols:\n",
    "    # Create a list of the numerical feature columns by excluding the target \n",
    "    features_to_plot = [col for col in num_cols if col != target]\n",
    "\n",
    "    # Loop through each numerical feature\n",
    "    for c in features_to_plot:\n",
    "        # Create a 6x4 figure for each plot\n",
    "        plt.figure(figsize=(6,4))\n",
    "        # Draw a scatter plot with the feature and the target\n",
    "        sns.scatterplot(x=df[c], y=df[target], alpha=0.5)\n",
    "        plt.title(f'{c} vs {target}')\n",
    "        plt.show()\n",
    "\n",
    "# 5. Countplots for categorical features (top categories)\n",
    "# Loop through first 6 categorical features\n",
    "for c in cat_cols[:6]:  \n",
    "    # Top = the 10 most common cetegories in the column \n",
    "    top = df[c].value_counts().nlargest(10).index\n",
    "    # Create 8x4 figure\n",
    "    plt.figure(figsize=(8,4))\n",
    "    # Draw bar chart of top most categorical features\n",
    "    sns.countplot(y=c, order=top, data=df)\n",
    "    plt.title(f'Top categories for {c}')\n",
    "    plt.show()\n",
    "\n",
    "# 6. Missingness Map\n",
    "# This provides a visual map of the entire raw dataset to show where missing values are.\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Initial Missing Value Matrix of Raw Data')\n",
    "plt.show()\n",
    "\n",
    "# 7. Boxplots of target vs categorical features (top categories)\n",
    "# Loop through each categorical column\n",
    "for c in cat_cols:\n",
    "    # To keep plots readable plot only the Top 10 most frequent categories \n",
    "    # 1. Get the names of the top 10 categories by frequency\n",
    "    top_10_cats = df[c].value_counts().nlargest(10).index    \n",
    "    # 2. Filter the DataFrame to only include rows with these top categories\n",
    "    # Use .copy() to avoid a SettingWithCopyWarning\n",
    "    df_top_10 = df[df[c].isin(top_10_cats)].copy()\n",
    "\n",
    "    # 3. Create the boxplot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(x=c, y=target, data=df_top_10, order=top_10_cats)\n",
    "    \n",
    "    plt.title(f'Price Distribution by {c} (Top 10 Categories)')\n",
    "    plt.xticks(rotation=45) \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f41809",
   "metadata": {},
   "source": [
    "## <font color=\"Blue\">Data Processing for Better Visualisation</font>\n",
    "\n",
    "Data processing for visualisation involves transforming and refining raw data to enhance the clarity and interpretability of exploratory plots. Unlike preprocessing for machine learning models, the primary goal here is to reveal underlying patterns and trends that might otherwise be obscured by noise, extreme outliers, or highly skewed scales.\n",
    "\n",
    "To facilitate this analysis, the following specific processing steps were implemented:\n",
    "\n",
    "**Feature Engineering & Cleaning:** A new vehicle_age feature was derived from the registration year to provide a more intuitive metric for depreciation. Additionally, invalid data (such as registration years prior to the invention of cars in 1886) was filtered out.\n",
    "\n",
    "**Normalising Skewed Distributions:** Logarithmic transformations were applied to the price and mileage features to correct their heavy right-skew, allowing for a clearer view of the central data distribution.\n",
    "\n",
    "**Outlier Management:** Extreme outliers in numerical columns were clipped to the 1st and 99th percentiles to prevent anomalies from distorting the scale of the graphs.\n",
    "\n",
    "**Binning Continuous Data:** The continuous mileage feature was grouped into categorical bins (e.g. '0-5k', '5k-20k') to facilitate the analysis of price trends across different life cycle stages of the vehicles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e8d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing and Feature Engineering for Visualisation\n",
    "\n",
    "# Create a copy of the dataframe for visualisation purposes to keep the original df clean.\n",
    "df_vis = df.copy()\n",
    "\n",
    "# Remove obvious Errors \n",
    "# Cars were invented in 1886, therefore, it is logical to assume any vehicle older 1886 is an Error\n",
    "# Also, any future year is invalid\n",
    "df_vis.loc[(df_vis['year_of_registration'] < 1886) | (df_vis['year_of_registration'] > datetime.now().year), 'year_of_registration'] = np.nan\n",
    "\n",
    "# Create vehicle_age from the registration year (current_year - year_of_registration) tunrning anything that can't be parsed to NaN instead of throwing an error\n",
    "df_vis['vehicle_age'] = datetime.now().year - pd.to_numeric(df_vis['year_of_registration'], errors='coerce')\n",
    "\n",
    "# Log transform right skewed numeric columns to improve distribution plots\n",
    "for c in ['price', 'mileage']:\n",
    "    if c in df_vis.columns and df_vis[c].min(skipna=True) >= 0:\n",
    "        df_vis[f'log_{c}'] = np.log1p(df_vis[c])\n",
    "\n",
    "# Clip extreme outliers in numeric columns for display (Top and Bottom 1%) \n",
    "for c in df_vis.select_dtypes(include='number').columns:\n",
    "    # Compute 1st and 99th percentiles\n",
    "    lo = df_vis[c].quantile(0.01)\n",
    "    hi = df_vis[c].quantile(0.99)\n",
    "    # Replace values outside the bounds with the boundary values\n",
    "    df_vis[c] = df_vis[c].clip(lower=lo, upper=hi)\n",
    "\n",
    "# Create mileage bins for easier plotting \n",
    "df_vis['mileage_bin'] = pd.cut(df_vis['mileage'], bins=[-1, 5000, 20000, 50000, 100000, 300000], labels=['0-5k','5k-20k','20k-50k','50k-100k','100k+'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a6fa42",
   "metadata": {},
   "source": [
    "### <font color=\"Blue\">Data Visualisation after Processing for Better Visualisation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9ea612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualisation after Preprocessing\n",
    "\n",
    "# Plot vehicle age\n",
    "plt.figure(figsize=(6, 3))\n",
    "if 'vehicle_age' in df_vis.columns:\n",
    "    sns.histplot(df_vis['vehicle_age'].dropna(), bins=30)\n",
    "    plt.title('vehicle age')\n",
    "    plt.xlabel('vehicle age')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Column 'vehicle_age' not found in df_vis. Run the preprocessing cell first.\")\n",
    "\n",
    "# Log transformed numerical columns\n",
    "log_cols_to_plot = [c for c in ['log_price', 'log_mileage'] if c in df_vis.columns]\n",
    "\n",
    "# Histograms of Transformed Numerical Columns\n",
    "for col in log_cols_to_plot:\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.histplot(df_vis[col].dropna(), kde=True, bins=30)\n",
    "    plt.title(f'{col} distribution')\n",
    "    plt.xlabel(col)\n",
    "    plt.show()\n",
    "\n",
    "# Top 10 categories Boxplots\n",
    "for c in cat_cols:\n",
    "    # Ensure the column exists in df_viz\n",
    "    if c not in df_vis.columns:\n",
    "        continue\n",
    "    top_10_cats = df_vis[c].value_counts().nlargest(10).index\n",
    "    if len(top_10_cats) == 0:\n",
    "        continue\n",
    "    df_top_10 = df_vis[df_vis[c].isin(top_10_cats)].copy()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    if 'log_price' in df_vis.columns:\n",
    "        sns.boxplot(x=c, y='log_price', data=df_top_10, order=top_10_cats)\n",
    "        plt.title(f'Price Distribution by {c} (Top 10 Categories)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Column 'log_price' not found in df_vis; skipping boxplot for {c}.\")\n",
    "\n",
    "# Plot price by mileage_bin using a boxplot\n",
    "plt.figure(figsize=(10,4))\n",
    "if 'mileage_bin' in df_vis.columns and 'log_price' in df_vis.columns:\n",
    "    sns.boxplot(x='mileage_bin', y='log_price', data=df_vis)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Price by mileage bin')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Columns 'mileage_bin' or 'log_price' missing in df_vis; ensure preprocessing ran.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a91f62",
   "metadata": {},
   "source": [
    "## <font color=\"Blue\">Data Processing for Machine Learning</font>\n",
    "\n",
    "This phase focused on transforming the raw dataset into a clean, numerical format suitable for model training while strictly adhering to best practices for preventing data leakage. Unlike exploratory analysis where the whole dataset may be viewed, processing for machine learning requires that all distributional parameters (such as medians for imputation, quantiles for outlier clipping, and means for scaling) be derived solely from the training set.\n",
    "\n",
    "To achieve this, the data processing was structured into two distinct stages:\n",
    "\n",
    "Stateless Transformations: Row-wise operations that do not depend on other samples, such as deriving vehicle_age from registration data and removing obvious errors (e.g. years < 1886), were performed globally to ensure data consistency.\n",
    "\n",
    "Stateful Transformations via Pipelines: The dataset was split into Training (80%) and Testing (20%) sets. Scikit-learn Pipelines were then constructed to encapsulate distinct processing logical flows for numerical and categorical data. This ensured that steps such as Median Imputation, Outlier Clipping (using a custom transformer based on the 1st and 99th percentiles of the training set), and Standard Scaling were fit only on X_train and legally applied to X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75172d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing for Machine Learning (operate on a copy `df_ml` to preserve `df`)\n",
    "\n",
    "# Define a function to derive the registration year from the 'reg_code'\n",
    "def reg_code_to_year(reg_code):\n",
    "    try:\n",
    "        code = int(float(reg_code))\n",
    "        if 51 <= code <= 99:\n",
    "            return 2000 + (code - 50)\n",
    "        elif 0 < code <= 50:\n",
    "            return 2000 + code\n",
    "        else:\n",
    "            return np.nan\n",
    "    except (ValueError, TypeError):\n",
    "        return np.nan\n",
    "\n",
    "# Work on a copy to avoid mutating the original `df`\n",
    "df_ml = df.copy()\n",
    "\n",
    "# Impute year or registration with derived year using reg_code_to_year function \n",
    "df_ml['derived_year'] = df_ml['reg_code'].apply(reg_code_to_year)\n",
    "df_ml['year_of_registration'] = df_ml['year_of_registration'].fillna(df_ml['derived_year']) if 'year_of_registration' in df_ml.columns else df_ml.get('year_of_registration')\n",
    "\n",
    "# Create vehicle age from year of registration since it is a more intuitive feature\n",
    "df_ml['vehicle_age'] = datetime.now().year - pd.to_numeric(df_ml.get('year_of_registration', pd.Series()), errors='coerce')\n",
    "\n",
    "# Create log price again\n",
    "df_ml['log_price'] = np.log1p(df_ml['price'])\n",
    "\n",
    "# Drop unneeded columns and clean\n",
    "cols_to_drop = ['public_reference', 'reg_code', 'year_of_registration', 'derived_year']\n",
    "df_ml.drop(columns=[c for c in cols_to_drop if c in df_ml.columns], inplace=True, errors='ignore')\n",
    "\n",
    "\n",
    "# Drop columns missing import features for prediciting\n",
    "correlated_missing_cols = [c for c in ['standard_colour', 'vehicle_condition', 'vehicle_age'] if c in df_ml.columns]\n",
    "if correlated_missing_cols:\n",
    "    df_ml.dropna(subset=correlated_missing_cols, how='all', inplace=True)\n",
    "\n",
    "# Drop duplicate columns\n",
    "df_ml.drop_duplicates(inplace=True)\n",
    "\n",
    "# Create missingness indicators on df_ml\n",
    "for c in df_ml.columns:\n",
    "    if df_ml[c].isna().any():\n",
    "        df_ml[f'{c}_missing'] = df_ml[c].isna().astype(int)\n",
    "\n",
    "# Define features (X) by dropping the target and related columns from df_ml\n",
    "cols_to_exclude = ['price', 'log_price', 'mileage_bin']\n",
    "X = df_ml.drop(columns=cols_to_exclude, axis=1, errors='ignore')\n",
    "y = df_ml['log_price'] \n",
    "\n",
    "# Ensure X and y are aligned by dropping rows where the target value is missing\n",
    "if hasattr(y, 'isnull') and y.isnull().any():\n",
    "    valid_indices = y.dropna().index\n",
    "    X = X.loc[valid_indices]\n",
    "    y = y.loc[valid_indices]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=99)\n",
    "\n",
    "# Copies to avoid SettingWithCopyWarning\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "\n",
    "# Numerical and categorical columns from training set\n",
    "num_cols_to_impute = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Imputation\n",
    "# Learn medians from the training set to avoid data leakage\n",
    "# Impute missing numerical data using the median\n",
    "imputer_num = SimpleImputer(strategy='median')\n",
    "# Fit the imputere on the training data and transforn it \n",
    "X_train[num_cols_to_impute] = imputer_num.fit_transform(X_train[num_cols_to_impute])\n",
    "# Fit the imputer on the test data using the median learned from the test data\n",
    "X_test[num_cols_to_impute] = imputer_num.transform(X_test[num_cols_to_impute])\n",
    "\n",
    "# Impute the missing categorical data with the mode\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "# Fit the imputer on the training data and transform it \n",
    "X_train[cat_cols] = imputer_cat.fit_transform(X_train[cat_cols])\n",
    "# Transform the test data using the mode learned from the training data\n",
    "X_test[cat_cols] = imputer_cat.transform(X_test[cat_cols])\n",
    "\n",
    "# Outlier clipping from training set to prevent data leakage\n",
    "num_cols_for_clipping = X_train.select_dtypes(include=['number']).columns\n",
    "for c in num_cols_for_clipping:\n",
    "    lo = X_train[c].quantile(0.01)\n",
    "    hi = X_train[c].quantile(0.99)\n",
    "    X_train[c] = X_train[c].clip(lower=lo, upper=hi)\n",
    "    X_test[c] = X_test[c].clip(lower=lo, upper=hi)\n",
    "\n",
    "# Group rare categories into 'Other' based on training frequencies to prevent data leakage\n",
    "for c in cat_cols:\n",
    "    freqs = X_train[c].value_counts(normalize=True)\n",
    "    rares = freqs[freqs < 0.01].index\n",
    "    X_train[c] = X_train[c].replace(list(rares), 'Other')\n",
    "    X_test[c] = X_test[c].replace(list(rares), 'Other')\n",
    "\n",
    "# Frequency enoding \n",
    "for c in cat_cols:\n",
    "    freq_map = X_train[c].value_counts(normalize=True)\n",
    "    X_train[f'{c}_freq'] = X_train[c].map(freq_map)\n",
    "    X_test[f'{c}_freq'] = X_test[c].map(freq_map).fillna(0)\n",
    "\n",
    "# Identify and Handle Low vs High Cardinality Categorical Features \n",
    "# High cardinality features >100 unique values will use target encoding (mean encoding) to avoid creating sparse high-dimensional outputs\n",
    "# Low cardinality features <=100 unique values will use one-hot encoding\n",
    "\n",
    "max_cardinality_threshold = 100\n",
    "low_card_cols = []\n",
    "high_card_cols = []\n",
    "\n",
    "# Seperate categorical columns based on cardinality\n",
    "for c in cat_cols:\n",
    "    n_unique = X_train[c].nunique()\n",
    "    if n_unique <= max_cardinality_threshold:\n",
    "        low_card_cols.append(c)\n",
    "    else:\n",
    "        high_card_cols.append(c)\n",
    "\n",
    "# Apply target encoding (mean encoding) to high cardinality features\n",
    "target_encodings = {}\n",
    "for c in high_card_cols:\n",
    "    target_means = y_train.groupby(X_train[c]).mean()\n",
    "    target_encodings[c] = target_means\n",
    "    # Map categories to their mean target value; fill unmapped values with overall mean\n",
    "    X_train[c] = X_train[c].map(target_means).fillna(y_train.mean())\n",
    "    X_test[c] = X_test[c].map(target_means).fillna(y_train.mean())\n",
    "\n",
    "# Update categorical columns list to only include low cardinality features for one hot encoding\n",
    "cat_cols = low_card_cols\n",
    "# Add high cardinality features to numerical columns, they are numeric after target encoding\n",
    "num_cols_to_impute.extend(high_card_cols)\n",
    "\n",
    "# Preprocessor for OneHotEncoding and Standard Scaler\n",
    "# This step prepares a 'preprocessor' object that will be used in the model building phase\n",
    "# It encapsulates the final transformations, scaling and one hot encoding\n",
    "\n",
    "# Get the final lists of numerical and categorical columns after the previous steps\n",
    "num_colsF = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "cat_colsF = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Define the transformer for one hot encoding categorical features (low-cardinality only)\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "# Define the transformer for standardising numerical features\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Combine the transformers into a single ColumnTransformer object\n",
    "# This object is not fitted here. It will be fitted on the training data within the model pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_colsF),\n",
    "        ('cat', categorical_transformer, cat_colsF)\n",
    "    ],\n",
    "    verbose_feature_names_out=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2ca551",
   "metadata": {},
   "source": [
    "### <font color=\"Blue\">Data Visualisation after Data Processing for Machine Learning</font>\n",
    "\n",
    "This section serves as a critical quality check, visualising the training data after all machine learning preprocessing steps have been applied. The aim is to verify that the transformations were effective before feeding the data to the models. The following plots confirm the success of key operations: the missing value heatmap validates that imputation is complete, histograms show the improved distributions of numerical features, and countplots display how rare categories were successfully grouped into an 'Other' category. These checks ensure the data is clean, robust, and properly formatted for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ffc4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Visualisation after Preprocessing for Machine Learning\n",
    "\n",
    "# The following plots use the X_train and y_train data to reflect the changes\n",
    "\n",
    "# Combine X_train and y_train for plotting purposes\n",
    "train_df_for_plotting = X_train.copy()\n",
    "train_df_for_plotting['log_price'] = y_train\n",
    "\n",
    "# Missingness Map after imputation\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(train_df_for_plotting.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title('Missing Value Matrix for Training Data after Imputation')\n",
    "plt.show()\n",
    "\n",
    "# Histograms of Imputed Numerical Columns\n",
    "# These plots show the distribution of key numerical features after missing values were filled\n",
    "print(\"Distribution of Numerical Features in the Training Set after imputation\")\n",
    "imputed_num_cols_to_plot = ['mileage', 'vehicle_age']\n",
    "for col in imputed_num_cols_to_plot:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(train_df_for_plotting[col], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of {col} in Training Set')\n",
    "    plt.show()\n",
    "\n",
    "# Countplots for Categorical Features after grouping rare categories\n",
    "# These plots show the new 'Other' category which groups all rare categories together\n",
    "print(\"\\nDistribution of Categorical Features in the Training Set after grouping\")\n",
    "for c in cat_cols: \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    # Order the bars by frequency\n",
    "    order = train_df_for_plotting[c].value_counts().index\n",
    "    sns.countplot(y=c, data=train_df_for_plotting, order=order)\n",
    "    plt.title(f'Top Categories for {c} in Training Set after grouping rares')\n",
    "    plt.show()\n",
    "\n",
    "# Boxplots of Target vs. Processed Categorical Features\n",
    "# This shows how the price is distributed across the processed categorical features, including the 'Other' group\n",
    "print(\"\\nPrice Distribution by Processed Categorical Features\")\n",
    "for c in cat_cols: \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # To keep plots readable use the value_counts index which is already ordered by frequency\n",
    "    order = train_df_for_plotting[c].value_counts().index\n",
    "    sns.boxplot(x=c, y='log_price', data=train_df_for_plotting, order=order)\n",
    "    plt.title(f'Price Distribution by {c} in Training Set')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Visualising Categorical Features without the 'Other' Category \n",
    "# Since the 'Other' category is very large and dominates the plots, make plots without it to better see the data\n",
    "for c in cat_cols:\n",
    "    # Create a temporary DataFrame for plotting that filters out the 'Other' category\n",
    "    df_filtered = train_df_for_plotting[train_df_for_plotting[c] != 'Other']\n",
    "    \n",
    "    if not df_filtered.empty:\n",
    "        # Countplot without 'Other' \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        order = df_filtered[c].value_counts().index\n",
    "        sns.countplot(y=c, data=df_filtered, order=order)\n",
    "        plt.title(f\"Top Categories for {c} without other\")\n",
    "        plt.show()\n",
    "\n",
    "        # Boxplot without 'Other'\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        order = df_filtered[c].value_counts().index\n",
    "        sns.boxplot(x=c, y='log_price', data=df_filtered, order=order)\n",
    "        plt.title(f\"Price Distribution by {c} without other\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Skipping plots for '{c}' as it only contains the 'Other' category after filtering.\")\n",
    "        \n",
    "# Histogram of a Target Encoded Column\n",
    "# This shows the distribution of the mean target values that replaced the original categories\n",
    "if high_card_cols: # Check if there are any high cardinality columns\n",
    "    col_to_plot = high_card_cols[0] # Plot the first one\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(train_df_for_plotting[col_to_plot], kde=True, bins=30)\n",
    "    plt.title(f'Distribution of Target-Encoded Feature: {col_to_plot}')\n",
    "    plt.xlabel('Mean Log Price')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20628249",
   "metadata": {},
   "source": [
    "## <font color=\"Blue\">Model Building</font>\n",
    "\n",
    "This section transitions from data preparation to the core task of predictive modeling. Here, three different regression models; K-Nearest Neighbors, Decision Tree, and Linear Regression and an ensemble; Random Forestm, are constructed and trained to predict vehicle prices. To ensure robustness and prevent data leakage, each model is embedded within a Scikit-learn Pipeline that chains the previously defined data preprocessor with the regressor. For the K-Nearest Neighbors and Decision Tree models, `GridSearchCV` is employed to systematically explore a range of hyperparameters and identify the optimal configuration for each, using cross-validation on a subset of the training data for efficiency. The Linear Regression model is evaluated using cross-validation before being trained on the entire training dataset. The final, best-performing version of each model is stored for the subsequent evaluation phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building \n",
    "\n",
    "# Instantiate Models as Pipelines \n",
    "# Create a pipeline for K-Nearest Neighbors\n",
    "knn_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "# Create a pipeline for Decision Tree\n",
    "dt_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=99))\n",
    "])\n",
    "\n",
    "# Create a pipeline for Linear Regression\n",
    "lr_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Create a pipeline for Random Forest Regressor\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "]) \n",
    "\n",
    "# Hyperparameter grids for GridSearch \n",
    "# Define the hyperparameter grid for KNN\n",
    "# Search for the best number of neighbors and weight scheme (uniform or distance which weights closer neighbours higher)\n",
    "knn_param_grid = {\n",
    "    'regressor__n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'regressor__weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Define the hyperparameter grid for Decision Tree\n",
    "dt_param_grid = {\n",
    "    'regressor__max_depth': [5, 10, 15, None],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Define the hyperparameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'regressor__n_estimators': [50, 100],\n",
    "    'regressor__max_depth': [10, 20, None],\n",
    "    'regressor__min_samples_split': [2, 5],\n",
    "}\n",
    "\n",
    "\n",
    "# Train Models and Tune using GridSearchCV\n",
    "print(\"Starting Model Training and Hyperparameter Tuning\")\n",
    "\n",
    "# Dictionary to store the fitted models\n",
    "fitted_models = {}\n",
    "# Keep grid search objects for later inspection\n",
    "grid_searches = {}\n",
    "\n",
    "# Grid Search Function\n",
    "def grid_search(pipeline, \n",
    "                param_grid, \n",
    "                X, y, \n",
    "                cv=3, \n",
    "                scoring={'r2': 'r2', 'neg_root_mean_squared_error': 'neg_root_mean_squared_error'}, \n",
    "                refit='r2', \n",
    "                name='model'):\n",
    "    gs = GridSearchCV(pipeline, \n",
    "                      param_grid, \n",
    "                      cv=cv, \n",
    "                      scoring=scoring, \n",
    "                      refit=refit, \n",
    "                      n_jobs=-1, \n",
    "                      return_train_score=True, \n",
    "                      verbose=1)\n",
    "    gs.fit(X, y)\n",
    "    return gs\n",
    "\n",
    "# To accelerate hyperparameter tuning train GridSearchCV on a smaller, random sample of the training data\n",
    "# This provides a good estimate of the best parameters much more quickly\n",
    "search_frac = 0.5\n",
    "X_search = X_train.sample(frac=search_frac, random_state=99)\n",
    "y_search = y_train.loc[X_search.index]\n",
    "print(f\"Note: Using a random {int(search_frac*100)}% subset of the training data ({len(X_search)} samples) to speed up tuning.\")\n",
    "\n",
    "# K-Nearest Neighbors Tuning\n",
    "print(\"\\nTuning K-Nearest Neighbors...\")\n",
    "knn_grid_search = grid_search(knn_pipeline, knn_param_grid, X_search, y_search, cv=3, name='KNN')\n",
    "\n",
    "# Store the best model found\n",
    "fitted_models['K-Nearest Neighbors'] = knn_grid_search.best_estimator_\n",
    "grid_searches['K-Nearest Neighbors'] = knn_grid_search\n",
    "\n",
    "# Output results\n",
    "print(\"\\nK-Nearest Neighbors Tuning Complete.\")\n",
    "print(f\"Best Parameters Found for KNN: {knn_grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation R-squared Score: {knn_grid_search.best_score_:.4f}\")\n",
    "best_rmse_knn = -knn_grid_search.cv_results_['mean_test_neg_root_mean_squared_error'][knn_grid_search.best_index_]\n",
    "print(f\"Best Cross-Validation RMSE (log scale): {best_rmse_knn:.4f}\")\n",
    "\n",
    "\n",
    "# Print top 5 configurations\n",
    "print(\"\\nTop 5 KNN Configurations:\")\n",
    "knn_results_df = pd.DataFrame(knn_grid_search.cv_results_).sort_values(by='rank_test_r2')\n",
    "knn_results_df['mean_test_rmse'] = -knn_results_df['mean_test_neg_root_mean_squared_error']\n",
    "knn_results_df['std_test_rmse'] = knn_results_df['std_test_neg_root_mean_squared_error']\n",
    "display(knn_results_df[['params', 'mean_test_r2', 'std_test_r2', 'mean_test_rmse', 'std_test_rmse']].head())\n",
    "\n",
    "\n",
    "# Decision Tree Tuning using sampled data to speed up tuning\n",
    "print('\\nTuning Decision Tree...')\n",
    "dt_grid_search = grid_search(dt_pipeline, dt_param_grid, X_search, y_search, cv=3, name='Decision Tree')\n",
    "\n",
    "# Store the best model found\n",
    "fitted_models['Decision Tree'] = dt_grid_search.best_estimator_\n",
    "grid_searches['Decision Tree'] = dt_grid_search\n",
    "\n",
    "# Output results\n",
    "print(\"\\nDecision Tree Tuning Complete.\")\n",
    "print(f'Best Parameters Found for Decision Tree: {dt_grid_search.best_params_}')\n",
    "print(f'Best Cross-Validation R-squared Score: {dt_grid_search.best_score_:.4f}')\n",
    "best_rmse_dt = -dt_grid_search.cv_results_['mean_test_neg_root_mean_squared_error'][dt_grid_search.best_index_]\n",
    "print(f\"Best Cross-Validation RMSE (log scale): {best_rmse_dt:.4f}\")\n",
    "\n",
    "# Display top 5 configurations\n",
    "print(\"\\nTop 5 Decision Tree Configurations:\")\n",
    "dt_results_df = pd.DataFrame(dt_grid_search.cv_results_).sort_values(by='rank_test_r2')\n",
    "dt_results_df['mean_test_rmse'] = -dt_results_df['mean_test_neg_root_mean_squared_error']\n",
    "dt_results_df['std_test_rmse'] = dt_results_df['std_test_neg_root_mean_squared_error']\n",
    "display(dt_results_df[['params', 'mean_test_r2', 'std_test_r2', 'mean_test_rmse', 'std_test_rmse']].head())\n",
    "\n",
    "\n",
    "# Linear Regression Evaluation \n",
    "print('\\nEvaluating Linear Regression...')\n",
    "# Linear Regression doesn't require extensive tuning, but cross validation is still helpful\n",
    "lr_cv_scores_r2 = cross_val_score(lr_pipeline, X_train, y_train, cv=3, scoring='r2', n_jobs=-1)\n",
    "print(f'Linear Regression Cross-Validation R-squared scores: {lr_cv_scores_r2}')\n",
    "print(f'Linear Regression Mean CV R-squared: {lr_cv_scores_r2.mean():.4f} (+/- {lr_cv_scores_r2.std():.4f})')\n",
    "\n",
    "# Calculate RMSE using cross-validation\n",
    "lr_cv_scores_rmse = cross_val_score(lr_pipeline, X_train, y_train, cv=3, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "print(f'\\nLinear Regression Cross-Validation RMSE scores (log scale): {-lr_cv_scores_rmse}')\n",
    "print(f'Linear Regression Mean CV RMSE (log scale): {-lr_cv_scores_rmse.mean():.4f} (+/- {lr_cv_scores_rmse.std():.4f})')\n",
    "\n",
    "# Fit the final linear regression model on the full training set\n",
    "print(\"\\nFitting final Linear Regression model on the full training data...\")\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "fitted_models['Linear Regression'] = lr_pipeline\n",
    "print(\"Linear Regression model fitted.\")\n",
    "\n",
    "# Random Forest Tuning using sampled data to speed up tuning\n",
    "print('\\nTuning Random Forest...')\n",
    "rf_grid_search = grid_search(rf_pipeline, rf_param_grid, X_search, y_search, cv=3, name='Random Forest')\n",
    "\n",
    "# Store the best model found\n",
    "fitted_models['Random Forest'] = rf_grid_search.best_estimator_\n",
    "grid_searches['Random Forest'] = rf_grid_search\n",
    "\n",
    "# Output results\n",
    "print(\"\\nRandom Forest Tuning Complete.\")\n",
    "print(f'Best Parameters Found for Random Forest: {rf_grid_search.best_params_}')\n",
    "print(f'Best Cross-Validation R-squared Score: {rf_grid_search.best_score_:.4f}')\n",
    "best_rmse_rf = -rf_grid_search.cv_results_['mean_test_neg_root_mean_squared_error'][rf_grid_search.best_index_]\n",
    "print(f\"Best Cross-Validation RMSE (log scale): {best_rmse_rf:.4f}\")\n",
    "\n",
    "# Display top 5 configurations\n",
    "print(\"\\nTop 5 Random Forest Configurations:\")\n",
    "rf_results_df = pd.DataFrame(rf_grid_search.cv_results_).sort_values(by='rank_test_r2')\n",
    "rf_results_df['mean_test_rmse'] = -rf_results_df['mean_test_neg_root_mean_squared_error']\n",
    "rf_results_df['std_test_rmse'] = rf_results_df['std_test_neg_root_mean_squared_error']\n",
    "display(rf_results_df[['params', 'mean_test_r2', 'std_test_r2', 'mean_test_rmse', 'std_test_rmse']].head())\n",
    "\n",
    "# Final Summary \n",
    "print('\\nModel building and tuning complete.')\n",
    "print('The best versions of all models are now stored in the fitted_models dictionary for analysis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d246ff5d",
   "metadata": {},
   "source": [
    "## <font color=\"Blue\">Model Evaluation and Analysis</font>\n",
    "\n",
    "This final stage provides a comprehensive evaluation of the trained models on the unseen test data. The analysis begins by calculating key performance metrics specifically Test Set R-squared (R²) and Root Mean Squared Error (RMSE) to create a quantitative comparison and identify the best performing model.\n",
    "\n",
    "To gain deeper insights into what drives the models' predictions, a Feature Importance Analysis is conducted. For the Linear Regression model, the feature coefficients are extracted and visualised to show the magnitude and direction of their influence. For the Decision Tree, the feature_importances_ attribute is used to rank features by their contribution to the model's predictive power.\n",
    "\n",
    "Finally, an Error Analysis is performed using residual plots, which graph the prediction errors against the predicted values. This helps diagnose any systematic issues and provides a better understanding of each model's strengths and weaknesses beyond single performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c861aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation and Analysis\n",
    "\n",
    "# Make Predictions and Evaluate Performance \n",
    "# List to store performance metrics for each model\n",
    "results = []\n",
    "# Dictionary used to store the actual predicted values for error analysis and residual plots\n",
    "predictions = {}\n",
    "\n",
    "# Iterate thorugh models to; make predictions, calculate metrics and print summary \n",
    "for name, model in fitted_models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    \n",
    "    # Make predictions on the test data.\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions[name] = y_pred\n",
    "    \n",
    "    # Inverse transform log_price values to original price scale\n",
    "    y_test_actual = np.expm1(y_test)\n",
    "    y_pred_actual = np.expm1(y_pred)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test_actual, y_pred_actual)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test_actual, y_pred_actual)\n",
    "    mape = mean_absolute_percentage_error(y_test_actual, y_pred_actual)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Append metrics to the results list\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Test Set R-squared (R2)': r2,\n",
    "        'Test Set RMSE (£)': rmse,\n",
    "        'Test Set MAE (£)': mae,\n",
    "        'Test Set MAPE (%)': mape * 100\n",
    "    })\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"  R-squared: {r2:.4f}\")\n",
    "    print(f\"  Root Mean Squared Error: £{rmse:,.2f}\")\n",
    "    print(f\"  Mean Absolute Error: £{mae:,.2f}\")\n",
    "    print(f\"  Mean Absolute Percentage Error: {mape*100:.2f}%\\n\")\n",
    "\n",
    "# Compare Models\n",
    "# Convert the results to a DataFrame for easy comparison\n",
    "results_df = pd.DataFrame(results).sort_values(by='Test Set R-squared (R2)', ascending=False)\n",
    "\n",
    "print(\"Final Model Comparison on Test Set\")\n",
    "display(results_df)\n",
    "\n",
    "# Visualise Predictions vs Actual Values for All Models (Scatter Plots)\n",
    "print(\"\\nActual vs Predicted Values for All Models (Scatter Plot)\")\n",
    "\n",
    "for name, y_pred in predictions.items():\n",
    "    # Inverse transform to actual price scale\n",
    "    y_test_actual = np.expm1(y_test)\n",
    "    y_pred_actual = np.expm1(y_pred)\n",
    "    \n",
    "    # Scatter plot of predicted vs actual\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.scatterplot(x=y_test_actual, y=y_pred_actual, alpha=0.5)\n",
    "    plt.plot([y_test_actual.min(), y_test_actual.max()], \n",
    "             [y_test_actual.min(), y_test_actual.max()], \n",
    "             '--', color='blue', linewidth=2, label='Perfect Prediction')\n",
    "    plt.title(f'\"{name}\" - Actual vs Predicted Prices (£)')\n",
    "    plt.xlabel('Actual Price (£)')\n",
    "    plt.ylabel('Predicted Price (£)')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualise Best Model's Predictions vs Actual Values (in £ scale)\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = fitted_models[best_model_name]\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Inverse transform BOTH to actual £ scale\n",
    "y_test_actual_best = np.expm1(y_test)\n",
    "y_pred_best_actual = np.expm1(y_pred_best)\n",
    "\n",
    "# DEBUG: Check the ranges\n",
    "print(f\"Actual prices - Min: £{y_test_actual_best.min():,.0f}, Max: £{y_test_actual_best.max():,.0f}, Mean: £{y_test_actual_best.mean():,.0f}\")\n",
    "print(f\"Predicted prices - Min: £{y_pred_best_actual.min():,.0f}, Max: £{y_pred_best_actual.max():,.0f}, Mean: £{y_pred_best_actual.mean():,.0f}\")\n",
    "print(f\"Y_test (log) - Min: {y_test.min():.2f}, Max: {y_test.max():.2f}\")\n",
    "print(f\"Y_pred (log) - Min: {y_pred_best.min():.2f}, Max: {y_pred_best.max():.2f}\")\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x=y_test_actual_best, y=y_pred_best_actual, alpha=0.5)\n",
    "plt.plot([y_test_actual_best.min(), y_test_actual_best.max()], \n",
    "         [y_test_actual_best.min(), y_test_actual_best.max()], \n",
    "         '--', color='red', linewidth=2, label='Perfect Prediction')\n",
    "plt.title(f'\"{best_model_name}\" - Actual vs Predicted Prices (£)')\n",
    "plt.xlabel('Actual Price (£)')\n",
    "plt.ylabel('Predicted Price (£)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance Analysis \n",
    "print(\"\\nFeature Importance Analysis\")\n",
    "\n",
    "# Linear Regression, plot coeeficients to show top 15 features with the biggest effect on the price\n",
    "lr_model = fitted_models.get('Linear Regression')\n",
    "# Get feature names and coefficients\n",
    "feature_names = lr_model.named_steps['preprocessor'].get_feature_names_out()\n",
    "coefficients = lr_model.named_steps['regressor'].coef_\n",
    "\n",
    "# Create dataframe to pair each feature with its coefficient \n",
    "coef_df = pd.DataFrame({'feature': feature_names, 'coefficient': coefficients})\n",
    "# Calculate the absolute value of the coefficients \n",
    "coef_df['abs_coefficient'] = np.abs(coef_df['coefficient'])\n",
    "# Sort in descending order and select top 15\n",
    "coef_df = coef_df.sort_values('abs_coefficient', ascending=False).head(15)\n",
    "        \n",
    "# Barplots of the top 15 features\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='coefficient', y='feature', data=coef_df)\n",
    "plt.title('Top 15 Feature Importances for Linear Regression')\n",
    "plt.xlabel('Coefficient')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree, plot features that best reduced impurity in leaf nodes, best predictors\n",
    "dt_model = fitted_models.get('Decision Tree')\n",
    "# Get feature names and importances\n",
    "feature_names = dt_model.named_steps['preprocessor'].get_feature_names_out()\n",
    "importances = dt_model.named_steps['regressor'].feature_importances_\n",
    "        \n",
    "# Dataframe to pair each feature with its importance \n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "importance_df = importance_df.sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "# Plot barplots of best predictors  \n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='importance', y='feature', data=importance_df)\n",
    "plt.title('Top 15 Feature Importances for Decision Tree')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "# Random Forest feature importance\n",
    "rf_model = fitted_models.get('Random Forest')\n",
    "if rf_model:\n",
    "    feature_names = rf_model.named_steps['preprocessor'].get_feature_names_out()\n",
    "    importances = rf_model.named_steps['regressor'].feature_importances_\n",
    "    \n",
    "    rf_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "    rf_importance_df = rf_importance_df.sort_values('importance', ascending=False).head(15)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x='importance', y='feature', data=rf_importance_df)\n",
    "    plt.title('Top 15 Feature Importances for Random Forest')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.show()\n",
    "\n",
    "# Error Analysis, Residual Plots\n",
    "print(\"\\nError Analysis: Residual Plots\")\n",
    "\n",
    "# Make plots of actual - predicted\n",
    "for name, y_pred in predictions.items():\n",
    "    residuals = y_test - y_pred\n",
    "    \n",
    "    # Plot scatter plot of predicted values and residuals with line of perfect prediction\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=y_pred, y=residuals, alpha=0.5)\n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    plt.title(f'Residual Plot for {name}')\n",
    "    plt.xlabel('Predicted Values (log_price)')\n",
    "    plt.ylabel('Residuals (Actual - Predicted)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e3ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered Actual vs Predicted Plots (Outliers Removed)\n",
    "print(\"FILTERED PLOTS: Actual vs Predicted Values (Outliers Removed)\")\n",
    "print(\"These plots exclude data points beyond the 1st and 99th percentiles to highlight typical model performance.\\n\")\n",
    "\n",
    "for name, y_pred in predictions.items():\n",
    "    # Inverse transform to actual price scale\n",
    "    y_test_actual = np.expm1(y_test)\n",
    "    y_pred_actual = np.expm1(y_pred)\n",
    "    \n",
    "    # Calculate percentiles for filtering (1st and 99th) using numpy percentile\n",
    "    actual_p1, actual_p99 = np.percentile(y_test_actual, [1, 99])\n",
    "    pred_p1, pred_p99 = np.percentile(y_pred_actual, [1, 99])\n",
    "    \n",
    "    # Create boolean mask for points within both ranges\n",
    "    mask = (y_test_actual >= actual_p1) & (y_test_actual <= actual_p99) & \\\n",
    "           (y_pred_actual >= pred_p1) & (y_pred_actual <= pred_p99)\n",
    "    \n",
    "    # Filter data\n",
    "    y_test_filtered = y_test_actual[mask]\n",
    "    y_pred_filtered = y_pred_actual[mask]\n",
    "    \n",
    "    # Count outliers removed\n",
    "    n_removed = (~mask).sum()\n",
    "    pct_removed = (n_removed / len(mask)) * 100\n",
    "    \n",
    "    # Create filtered scatter plot\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.scatterplot(x=y_test_filtered, y=y_pred_filtered, alpha=0.5)\n",
    "    plt.plot([y_test_filtered.min(), y_test_filtered.max()], \n",
    "             [y_test_filtered.min(), y_test_filtered.max()], \n",
    "             '--', color='red', linewidth=2, label='Perfect Prediction')\n",
    "    plt.title(f'\"{name}\" - Actual vs Predicted Prices (£)\\n(Filtered: {n_removed} outliers removed, {pct_removed:.1f}%)')\n",
    "    plt.xlabel('Actual Price (£)')\n",
    "    plt.ylabel('Predicted Price (£)')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics for filtered data\n",
    "    print(f\"{name} (Filtered):\")\n",
    "    print(f\"  Points removed: {n_removed} ({pct_removed:.1f}%)\")\n",
    "    print(f\"  Actual prices - Min: £{y_test_filtered.min():,.0f}, Max: £{y_test_filtered.max():,.0f}\")\n",
    "    print(f\"  Predicted prices - Min: £{y_pred_filtered.min():,.0f}, Max: £{y_pred_filtered.max():,.0f}\\n\")\n",
    "\n",
    "# Filtered plot for Best Model\n",
    "print(f\"FILTERED PLOT: Best Model ({best_model_name})\")\n",
    "\n",
    "y_test_actual_best = np.expm1(y_test)\n",
    "y_pred_best_actual = np.expm1(y_pred_best)\n",
    "\n",
    "# Calculate percentiles using numpy percentile\n",
    "actual_p1, actual_p99 = np.percentile(y_test_actual_best, [1, 99])\n",
    "pred_p1, pred_p99 = np.percentile(y_pred_best_actual, [1, 99])\n",
    "\n",
    "# Create mask\n",
    "mask_best = (y_test_actual_best >= actual_p1) & (y_test_actual_best <= actual_p99) & \\\n",
    "            (y_pred_best_actual >= pred_p1) & (y_pred_best_actual <= pred_p99)\n",
    "\n",
    "# Filter data\n",
    "y_test_best_filtered = y_test_actual_best[mask_best]\n",
    "y_pred_best_filtered = y_pred_best_actual[mask_best]\n",
    "\n",
    "n_removed_best = (~mask_best).sum()\n",
    "pct_removed_best = (n_removed_best / len(mask_best)) * 100\n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x=y_test_best_filtered, y=y_pred_best_filtered, alpha=0.5)\n",
    "plt.plot([y_test_best_filtered.min(), y_test_best_filtered.max()], \n",
    "         [y_test_best_filtered.min(), y_test_best_filtered.max()], \n",
    "         '--', color='red', linewidth=2, label='Perfect Prediction')\n",
    "plt.title(f'\"{best_model_name}\" - Actual vs Predicted Prices (£) - Filtered\\n({n_removed_best} outliers removed, {pct_removed_best:.1f}%)')\n",
    "plt.xlabel('Actual Price (£)')\n",
    "plt.ylabel('Predicted Price (£)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
